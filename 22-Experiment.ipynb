{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79a809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "  Iteration 0 finished before timeout\n",
      "Starting iteration 1\n",
      "  Iteration 1 finished before timeout\n",
      "Starting iteration 2\n",
      "  Iteration 2 finished before timeout\n",
      "Starting iteration 3\n",
      "  Iteration 3 finished before timeout\n",
      "Starting iteration 4\n",
      "  Iteration 4 finished before timeout\n",
      "Loop finished.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def work(i):\n",
    "    # put your long computation here\n",
    "    time.sleep(100)   # simulate a long task\n",
    "    return f\"done {i}\"\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Starting iteration {i}\")\n",
    "\n",
    "    p = mp.Process(target=work, args=(i,))\n",
    "    p.start()\n",
    "    p.join(20)  # wait max 20 seconds\n",
    "\n",
    "    if p.is_alive():\n",
    "        print(f\"  Iteration {i} timed out\")\n",
    "        p.terminate()\n",
    "        p.join()\n",
    "    else:\n",
    "        print(f\"  Iteration {i} finished before timeout\")\n",
    "\n",
    "print(\"Loop finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd65c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ot.backend.NumpyBackend, ot.backend.TorchBackend]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ot\n",
    "from ot.backend import get_backend\n",
    "ot.backend.get_available_backend_implementations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc831af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian norm: tensor(11.2250)\n",
      "tensor(3.) tensor(3.)\n",
      "tensor(6.) tensor(6.)\n",
      "tensor(9.) tensor(9.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jacobian\n",
    "\n",
    "Cs = torch.stack([\n",
    "    torch.ones(3,3)*1,\n",
    "    torch.ones(3,3)*2,\n",
    "    torch.ones(3,3)*3,\n",
    "])\n",
    "\n",
    "def f(lam):\n",
    "    weights = lam.view(-1,1,1)\n",
    "    return (weights * Cs).sum(dim=0)\n",
    "\n",
    "lam = torch.tensor([0.3,0.3,0.4], requires_grad=True)\n",
    "\n",
    "J = jacobian(f, lam)\n",
    "print(\"Jacobian norm:\", J.norm())\n",
    "print(J[:, :, 0].norm(), Cs[0].norm())  # should match!\n",
    "print(J[:, :, 1].norm(), Cs[1].norm())\n",
    "print(J[:, :, 2].norm(), Cs[2].norm())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
